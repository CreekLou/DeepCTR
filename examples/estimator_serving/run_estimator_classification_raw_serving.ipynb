{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr.estimator.inputs import input_fn_pandas\n",
    "from deepctr.estimator import DeepFMEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../criteo_sample.txt')\n",
    "sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']\n",
    "df = data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integer_mapping(le):\n",
    "    '''\n",
    "    Return a dict mapping labels to their integer values from an SKlearn LabelEncoder\n",
    "    le = a fitted SKlearn LabelEncoder\n",
    "    '''\n",
    "    res = {}\n",
    "    for idx, val in enumerate(le.classes_):\n",
    "        res.update({val:idx})\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "feat_index_dict = {} \n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "    feat_index_dict.update({feat:get_integer_mapping(lbe)})\n",
    "\n",
    "# save min max value for each dense feature \n",
    "s_max,s_min = data[dense_features].max(axis=0),data[dense_features].min(axis=0)\n",
    "pd.concat([s_max, s_min],keys=['max','min'],axis=1).to_csv(f\"max_min.txt\",sep=\"\\t\")\n",
    "    \n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "#  save category features index for serving stage\n",
    "import json\n",
    "with open(\"feat_index_dict.json\", 'w') as fo:\n",
    "    json.dump(feat_index_dict, fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field,and record dense feature field name\n",
    "dnn_feature_columns = []\n",
    "linear_feature_columns = []\n",
    "for i, feat in enumerate(sparse_features):\n",
    "    dnn_feature_columns.append(tf.feature_column.embedding_column(\n",
    "        tf.feature_column.categorical_column_with_identity(feat, data[feat].nunique()), 4))\n",
    "    linear_feature_columns.append(tf.feature_column.categorical_column_with_identity(feat, data[feat].nunique()))\n",
    "for feat in dense_features:\n",
    "    dnn_feature_columns.append(tf.feature_column.numeric_column(feat))\n",
    "    linear_feature_columns.append(tf.feature_column.numeric_column(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/inputs.py:28: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/inputs.py:28: The name tf.estimator.inputs.pandas_input_fn is deprecated. Please use tf.compat.v1.estimator.inputs.pandas_input_fn instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3.generate input data for model\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "# Not setting default value for continuous feature. filled with mean.\n",
    "train_model_input = input_fn_pandas(train,sparse_features+dense_features,'label')\n",
    "test_model_input = input_fn_pandas(test,sparse_features+dense_features,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmptmz7m48o\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmptmz7m48o', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f37c20aa080>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:155: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/feature_column.py:11: The name tf.feature_column.linear_model is deprecated. Please use tf.compat.v1.feature_column.linear_model instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:554: IdentityCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:556: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:2040: IdentityCategoricalColumn._get_sparse_tensors (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: IdentityCategoricalColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/ops/embedding_ops.py:802: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:558: NumericColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:1941: NumericColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:2158: NumericColumn._transform_feature (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:176: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:169: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/feature_column.py:25: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:190: The name tf.feature_column.input_layer is deprecated. Please use tf.compat.v1.feature_column.input_layer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:206: EmbeddingColumn._get_dense_tensor (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py:207: EmbeddingColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/layers/utils.py:164: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:95: The name tf.losses.get_regularization_loss is deprecated. Please use tf.compat.v1.losses.get_regularization_loss instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:131: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/deepctr/estimator/utils.py:147: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/training/monitored_session.py:882: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmptmz7m48o/model.ckpt.\n",
      "INFO:tensorflow:loss = 1685.0953, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmptmz7m48o/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1685.0953.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptmz7m48o/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "test LogLoss 1.2863\n",
      "test AUC 0.7083\n"
     ]
    }
   ],
   "source": [
    "# 4.Define Model,train,predict and evaluate\n",
    "model = DeepFMEstimator(linear_feature_columns, dnn_feature_columns)\n",
    "model.train(train_model_input)\n",
    "pred_ans_iter = model.predict(test_model_input)\n",
    "pred_ans = list(map(lambda x:x['pred'],pred_ans_iter))\n",
    "#\n",
    "print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-49a3a91c1275>:11: Estimator.export_savedmodel (from tensorflow_estimator.python.estimator.estimator) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function has been renamed, use `export_saved_model` instead.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmptmz7m48o/model.ckpt-1\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./serving_raw/temp-b'1593253204'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'./serving_raw/1593253204'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.saved Model by build_raw_serving_input\n",
    "def serving_input_receiver_fn():\n",
    "    feature_map = {}\n",
    "    for i in range(len(sparse_features)):\n",
    "        feature_map[sparse_features[i]] = tf.placeholder(tf.int32,shape=(None, ),name='{}'.format(sparse_features[i]))\n",
    "    for i in range(len(dense_features)):\n",
    "        feature_map[dense_features[i]] = tf.placeholder(tf.float32,shape=(None, ),name='{}'.format(dense_features[i]))\n",
    "    return tf.estimator.export.build_raw_serving_input_receiver_fn(feature_map)\n",
    "       \n",
    "model.export_savedmodel(export_dir_base='./serving_raw/',\n",
    "                             serving_input_receiver_fn=serving_input_receiver_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['predict']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['C1'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C1:0\n",
      "    inputs['C10'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C10:0\n",
      "    inputs['C11'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C11:0\n",
      "    inputs['C12'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C12:0\n",
      "    inputs['C13'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C13:0\n",
      "    inputs['C14'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C14:0\n",
      "    inputs['C15'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C15:0\n",
      "    inputs['C16'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C16:0\n",
      "    inputs['C17'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C17:0\n",
      "    inputs['C18'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C18:0\n",
      "    inputs['C19'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C19:0\n",
      "    inputs['C2'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C2:0\n",
      "    inputs['C20'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C20:0\n",
      "    inputs['C21'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C21:0\n",
      "    inputs['C22'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C22:0\n",
      "    inputs['C23'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C23:0\n",
      "    inputs['C24'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C24:0\n",
      "    inputs['C25'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C25:0\n",
      "    inputs['C26'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C26:0\n",
      "    inputs['C3'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C3:0\n",
      "    inputs['C4'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C4:0\n",
      "    inputs['C5'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C5:0\n",
      "    inputs['C6'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C6:0\n",
      "    inputs['C7'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C7:0\n",
      "    inputs['C8'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C8:0\n",
      "    inputs['C9'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C9:0\n",
      "    inputs['I1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I1:0\n",
      "    inputs['I10'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I10:0\n",
      "    inputs['I11'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I11:0\n",
      "    inputs['I12'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I12:0\n",
      "    inputs['I13'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I13:0\n",
      "    inputs['I2'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I2:0\n",
      "    inputs['I3'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I3:0\n",
      "    inputs['I4'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I4:0\n",
      "    inputs['I5'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I5:0\n",
      "    inputs['I6'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I6:0\n",
      "    inputs['I7'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I7:0\n",
      "    inputs['I8'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I8:0\n",
      "    inputs['I9'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I9:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['logits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/Reshape:0\n",
      "    outputs['pred'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/Sigmoid:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['C1'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C1:0\n",
      "    inputs['C10'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C10:0\n",
      "    inputs['C11'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C11:0\n",
      "    inputs['C12'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C12:0\n",
      "    inputs['C13'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C13:0\n",
      "    inputs['C14'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C14:0\n",
      "    inputs['C15'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C15:0\n",
      "    inputs['C16'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C16:0\n",
      "    inputs['C17'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C17:0\n",
      "    inputs['C18'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C18:0\n",
      "    inputs['C19'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C19:0\n",
      "    inputs['C2'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C2:0\n",
      "    inputs['C20'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C20:0\n",
      "    inputs['C21'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C21:0\n",
      "    inputs['C22'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C22:0\n",
      "    inputs['C23'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C23:0\n",
      "    inputs['C24'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C24:0\n",
      "    inputs['C25'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C25:0\n",
      "    inputs['C26'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C26:0\n",
      "    inputs['C3'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C3:0\n",
      "    inputs['C4'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C4:0\n",
      "    inputs['C5'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C5:0\n",
      "    inputs['C6'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C6:0\n",
      "    inputs['C7'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C7:0\n",
      "    inputs['C8'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C8:0\n",
      "    inputs['C9'] tensor_info:\n",
      "        dtype: DT_INT32\n",
      "        shape: (-1)\n",
      "        name: C9:0\n",
      "    inputs['I1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I1:0\n",
      "    inputs['I10'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I10:0\n",
      "    inputs['I11'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I11:0\n",
      "    inputs['I12'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I12:0\n",
      "    inputs['I13'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I13:0\n",
      "    inputs['I2'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I2:0\n",
      "    inputs['I3'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I3:0\n",
      "    inputs['I4'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I4:0\n",
      "    inputs['I5'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I5:0\n",
      "    inputs['I6'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I6:0\n",
      "    inputs['I7'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I7:0\n",
      "    inputs['I8'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I8:0\n",
      "    inputs['I9'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1)\n",
      "        name: I9:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['logits'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/Reshape:0\n",
      "    outputs['pred'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 1)\n",
      "        name: head/Sigmoid:0\n",
      "  Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "export_path = './serving_raw/1593253204'\n",
    "!saved_model_cli show --dir {export_path} --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-27 18:20:26.313669: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-06-27 18:20:26.313695: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-06-27 18:20:26.313709: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mi-OptiPlex-9020): /proc/driver/nvidia/version does not exist\n",
      "2020-06-27 18:20:26.313898: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-06-27 18:20:26.334813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3591625000 Hz\n",
      "2020-06-27 18:20:26.335290: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557a14ef3e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-06-27 18:20:26.335320: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /home/mi/anaconda3/envs/tf1x/lib/python3.6/site-packages/tensorflow_core/python/tools/saved_model_cli.py:420: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "Result for output key logits:\n",
      "[[-7.176791  ]\n",
      " [-3.2864132 ]\n",
      " [-0.9394809 ]\n",
      " [ 3.079597  ]\n",
      " [-0.65539366]]\n",
      "Result for output key pred:\n",
      "[[7.6353236e-04]\n",
      " [3.6040250e-02]\n",
      " [2.8100520e-01]\n",
      " [9.5604318e-01]\n",
      " [3.4177512e-01]]\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli run --dir {export_path} --tag_set serve --signature_def \"serving_default\" --input_expr 'I1=[0.0,0.0,0.0,0.0,0.0];I2=[0.001332,0.0,0.000333,0.004664,0.000333];I3=[0.092362,0.00675,0.00071,0.000355,0.036945];I4=[0.0,0.402298,0.137931,0.045977,0.310344];I5=[0.034825,0.059628,0.003968,0.033185,0.003922];I6=[0.0,0.117284,0.077873,0.094967,0.067426];I7=[0.0,0.003322,0.019934,0.016611,0.013289];I8=[0.673468,0.714284,0.714284,0.081632,0.65306];I9=[0.0,0.154739,0.505803,0.028046,0.035783];I10=[0.0,0.0,0.0,0.0,0.0];I11=[0.0,0.03125,0.09375,0.0625,0.03125];I12=[0.0,0.0,0.0,0.0,0.0];I13=[0.0,0.343137,0.17647,0.039216,0.264706];C1=[0,11,0,0,0];C2=[4,1,18,45,11];C3=[96,98,39,7,59];C4=[146,98,52,117,77];C5=[1,1,3,1,1];C6=[4,6,4,0,5];C7=[163,179,140,164,18];C8=[1,0,2,1,1];C9=[1,1,1,0,1];C10=[72,89,93,20,45];C11=[117,58,31,61,171];C12=[127,97,122,104,162];C13=[157,79,16,36,96];C14=[7,7,7,1,4];C15=[127,72,129,43,36];C16=[126,26,97,43,121];C17=[8,7,8,8,8];C18=[66,52,49,37,14];C19=[0,0,0,0,5];C20=[0,0,0,0,3];C21=[3,47,25,156,9];C22=[0,0,0,0,0];C23=[1,7,6,0,0];C24=[96,112,53,32,5];C25=[0,0,0,0,1];C26=[0,0,0,0,47]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local pc\n",
    "import os\n",
    "os.environ[\"MODEL_DIR\"] = '/home/mi/openwork/sub/DeepCTR/examples/estimator_serving/serving_raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " %%bash --bg \n",
    "nohup tensorflow_model_server \\\n",
    "--port=8500 \\\n",
    "--rest_api_port=8501 \\\n",
    "--model_name=raw_export_deepfm_model \\\n",
    "--model_base_path=${MODEL_DIR} >server.log 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make some samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read for category feature\n",
    "with open(\"feat_index_dict.json\") as fi:\n",
    "    sparse_dict = json.load(fi)\n",
    "    \n",
    "# load minmax dict for each dense feature\n",
    "df_dense_dict = pd.read_csv(\"./max_min.txt\",sep=\"\\t\",names=['fea_name','max','min'],skiprows=1)\n",
    "dense_dict = dict(zip(df_dense_dict['fea_name'],zip(df_dense_dict['max'], df_dense_dict['min'])))\n",
    "def get_normal(k,v):\n",
    "    return round((v - dense_dict[k][1])/(dense_dict[k][0]-dense_dict[k][1]+1e-4),6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_insts = []\n",
    "for index, row in df.iterrows():\n",
    "#     print(row['I1'],row['C2'])\n",
    "    inst_dict = {}\n",
    "    for feat in dense_features:\n",
    "        normal_value = get_normal(feat,row[feat])\n",
    "        inst_dict.update({feat:normal_value})\n",
    "    for feat in sparse_features:\n",
    "        inst_dict.update({feat:sparse_dict[feat][row[feat]]})\n",
    "    print(inst_dict)\n",
    "    print(\"-\"*50)\n",
    "    example_insts.append(inst_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST for raw tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "fea_dict1 = {'I1':[0.0],'I2':[0.001332],'I3':[0.092362],'I4':[0.0],'I5':[0.034825],'I6':[0.0],'I7':[0.0],'I8':[0.673468],'I9':[0.0],'I10':[0.0],'I11':[0.0],'I12':[0.0],'I13':[0.0],'C1':[0],'C2':[4],'C3':[96],'C4':[146],'C5':[1],'C6':[4],'C7':[163],'C8':[1],'C9':[1],'C10':[72],'C11':[117],'C12':[127],'C13':[157],'C14':[7],'C15':[127],'C16':[126],'C17':[8],'C18':[66],'C19':[0],'C20':[0],'C21':[3],'C22':[0],'C23':[1],'C24':[96],'C25':[0],'C26':[0]}\n",
    "fea_dict2 = {'I1':[0.0],'I2':[0.0],'I3':[0.00675],'I4':[0.402298],'I5':[0.059628],'I6':[0.117284],'I7':[0.003322],'I8':[0.714284],'I9':[0.154739],'I10':[0.0],'I11':[0.03125],'I12':[0.0],'I13':[0.343137],'C1':[11],'C2':[1],'C3':[98],'C4':[98],'C5':[1],'C6':[6],'C7':[179],'C8':[0],'C9':[1],'C10':[89],'C11':[58],'C12':[97],'C13':[79],'C14':[7],'C15':[72],'C16':[26],'C17':[7],'C18':[52],'C19':[0],'C20':[0],'C21':[47],'C22':[0],'C23':[7],'C24':[112],'C25':[0],'C26':[0]}\n",
    "fea_dict3 = {'I1':[0.0],'I2':[0.000333],'I3':[0.00071],'I4':[0.137931],'I5':[0.003968],'I6':[0.077873],'I7':[0.019934],'I8':[0.714284],'I9':[0.505803],'I10':[0.0],'I11':[0.09375],'I12':[0.0],'I13':[0.17647],'C1':[0],'C2':[18],'C3':[39],'C4':[52],'C5':[3],'C6':[4],'C7':[140],'C8':[2],'C9':[1],'C10':[93],'C11':[31],'C12':[122],'C13':[16],'C14':[7],'C15':[129],'C16':[97],'C17':[8],'C18':[49],'C19':[0],'C20':[0],'C21':[25],'C22':[0],'C23':[6],'C24':[53],'C25':[0],'C26':[0]}\n",
    "fea_dict4 = {'I1':[0.0],'I2':[0.004664],'I3':[0.000355],'I4':[0.045977],'I5':[0.033185],'I6':[0.094967],'I7':[0.016611],'I8':[0.081632],'I9':[0.028046],'I10':[0.0],'I11':[0.0625],'I12':[0.0],'I13':[0.039216],'C1':[0],'C2':[45],'C3':[7],'C4':[117],'C5':[1],'C6':[0],'C7':[164],'C8':[1],'C9':[0],'C10':[20],'C11':[61],'C12':[104],'C13':[36],'C14':[1],'C15':[43],'C16':[43],'C17':[8],'C18':[37],'C19':[0],'C20':[0],'C21':[156],'C22':[0],'C23':[0],'C24':[32],'C25':[0],'C26':[0]}\n",
    "fea_dict5 = {'I1':[0.0],'I2':[0.000333],'I3':[0.036945],'I4':[0.310344],'I5':[0.003922],'I6':[0.067426],'I7':[0.013289],'I8':[0.65306],'I9':[0.035783],'I10':[0.0],'I11':[0.03125],'I12':[0.0],'I13':[0.264706],'C1':[0],'C2':[11],'C3':[59],'C4':[77],'C5':[1],'C6':[5],'C7':[18],'C8':[1],'C9':[1],'C10':[45],'C11':[171],'C12':[162],'C13':[96],'C14':[4],'C15':[36],'C16':[121],'C17':[8],'C18':[14],'C19':[5],'C20':[3],'C21':[9],'C22':[0],'C23':[0],'C24':[5],'C25':[1],'C26':[47]}\n",
    "\n",
    "# json str\n",
    "data = json.dumps({\"signature_name\": \"serving_default\",\"instances\": [fea_dict1,fea_dict2,fea_dict3,fea_dict4,fea_dict5] })\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'logits': [-7.17679119], 'pred': [0.000763532356]},\n",
       "  {'logits': [-3.28641319], 'pred': [0.0360402502]},\n",
       "  {'logits': [-0.939480901], 'pred': [0.281005204]},\n",
       "  {'logits': [3.079597], 'pred': [0.956043184]},\n",
       "  {'logits': [-0.65539366], 'pred': [0.341775119]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -q requests\n",
    "import requests \n",
    "json_response = requests.post('http://localhost:8501/v1/models/raw_export_deepfm_model:predict', data=data)\n",
    "predictions = json.loads(json_response.text)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRPC for raw tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow-serving-api=='1.12.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:[[-7.17679119]\n",
      " [-3.28641319]\n",
      " [-0.9394809 ]\n",
      " [ 3.079597  ]\n",
      " [-0.65539366]]\n",
      "pred:[[7.63532356e-04]\n",
      " [3.60402502e-02]\n",
      " [2.81005204e-01]\n",
      " [9.56043184e-01]\n",
      " [3.41775119e-01]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import grpc\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow_serving.apis import predict_pb2\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "\n",
    "channel = grpc.insecure_channel(target='0.0.0.0:8500')\n",
    "stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "\n",
    "request = predict_pb2.PredictRequest()\n",
    "request.model_spec.name = 'raw_export_deepfm_model'\n",
    "request.model_spec.signature_name = 'serving_default'\n",
    "\n",
    " \n",
    "request.inputs['I1'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.0,0.0,0.0,0.0], shape=[5]))\n",
    "request.inputs['I2'].CopyFrom(tf.contrib.util.make_tensor_proto([0.001332,0.0,0.000333,0.004664,0.000333], shape=[5]))\n",
    "request.inputs['I3'].CopyFrom(tf.contrib.util.make_tensor_proto([0.092362,0.00675,0.00071,0.000355,0.036945], shape=[5]))\n",
    "request.inputs['I4'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.402298,0.137931,0.045977,0.310344], shape=[5]))\n",
    "request.inputs['I5'].CopyFrom(tf.contrib.util.make_tensor_proto([0.034825,0.059628,0.003968,0.033185,0.003922], shape=[5]))\n",
    "request.inputs['I6'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.117284,0.077873,0.094967,0.067426], shape=[5]))\n",
    "request.inputs['I7'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.003322,0.019934,0.016611,0.013289], shape=[5]))\n",
    "request.inputs['I8'].CopyFrom(tf.contrib.util.make_tensor_proto([0.673468,0.714284,0.714284,0.081632,0.65306], shape=[5]))\n",
    "request.inputs['I9'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.154739,0.505803,0.028046,0.035783], shape=[5]))\n",
    "request.inputs['I10'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.0,0.0,0.0,0.0], shape=[5]))\n",
    "request.inputs['I11'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.03125,0.09375,0.0625,0.03125], shape=[5]))\n",
    "request.inputs['I12'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.0,0.0,0.0,0.0], shape=[5]))\n",
    "request.inputs['I13'].CopyFrom(tf.contrib.util.make_tensor_proto([0.0,0.343137,0.17647,0.039216,0.264706], shape=[5]))\n",
    "\n",
    "request.inputs['C1'].CopyFrom(tf.contrib.util.make_tensor_proto([0,11,0,0,0], shape=[5]))\n",
    "request.inputs['C2'].CopyFrom(tf.contrib.util.make_tensor_proto([4,1,18,45,11], shape=[5]))\n",
    "request.inputs['C3'].CopyFrom(tf.contrib.util.make_tensor_proto([96,98,39,7,59], shape=[5]))\n",
    "request.inputs['C4'].CopyFrom(tf.contrib.util.make_tensor_proto([146,98,52,117,77], shape=[5]))\n",
    "request.inputs['C5'].CopyFrom(tf.contrib.util.make_tensor_proto([1,1,3,1,1], shape=[5]))\n",
    "request.inputs['C6'].CopyFrom(tf.contrib.util.make_tensor_proto([4,6,4,0,5], shape=[5]))\n",
    "request.inputs['C7'].CopyFrom(tf.contrib.util.make_tensor_proto([163,179,140,164,18], shape=[5]))\n",
    "request.inputs['C8'].CopyFrom(tf.contrib.util.make_tensor_proto([1,0,2,1,1], shape=[5]))\n",
    "request.inputs['C9'].CopyFrom(tf.contrib.util.make_tensor_proto([1,1,1,0,1], shape=[5]))\n",
    "request.inputs['C10'].CopyFrom(tf.contrib.util.make_tensor_proto([72,89,93,20,45], shape=[5]))\n",
    "request.inputs['C11'].CopyFrom(tf.contrib.util.make_tensor_proto([117,58,31,61,171], shape=[5]))\n",
    "request.inputs['C12'].CopyFrom(tf.contrib.util.make_tensor_proto([127,97,122,104,162], shape=[5]))\n",
    "request.inputs['C13'].CopyFrom(tf.contrib.util.make_tensor_proto([157,79,16,36,96], shape=[5]))\n",
    "request.inputs['C14'].CopyFrom(tf.contrib.util.make_tensor_proto([7,7,7,1,4], shape=[5]))\n",
    "request.inputs['C15'].CopyFrom(tf.contrib.util.make_tensor_proto([127,72,129,43,36], shape=[5]))\n",
    "request.inputs['C16'].CopyFrom(tf.contrib.util.make_tensor_proto([126,26,97,43,121], shape=[5]))\n",
    "request.inputs['C17'].CopyFrom(tf.contrib.util.make_tensor_proto([8,7,8,8,8], shape=[5]))\n",
    "request.inputs['C18'].CopyFrom(tf.contrib.util.make_tensor_proto([66,52,49,37,14], shape=[5]))\n",
    "request.inputs['C19'].CopyFrom(tf.contrib.util.make_tensor_proto([0,0,0,0,5], shape=[5]))\n",
    "request.inputs['C20'].CopyFrom(tf.contrib.util.make_tensor_proto([0,0,0,0,3], shape=[5]))\n",
    "request.inputs['C21'].CopyFrom(tf.contrib.util.make_tensor_proto([3,47,25,156,9], shape=[5]))\n",
    "request.inputs['C22'].CopyFrom(tf.contrib.util.make_tensor_proto([0,0,0,0,0], shape=[5]))\n",
    "request.inputs['C23'].CopyFrom(tf.contrib.util.make_tensor_proto([1,7,6,0,0], shape=[5]))\n",
    "request.inputs['C24'].CopyFrom(tf.contrib.util.make_tensor_proto([96,112,53,32,5], shape=[5]))\n",
    "request.inputs['C25'].CopyFrom(tf.contrib.util.make_tensor_proto([0,0,0,0,1], shape=[5]))\n",
    "request.inputs['C26'].CopyFrom(tf.contrib.util.make_tensor_proto([0,0,0,0,47], shape=[5]))\n",
    "\n",
    "\n",
    "result = stub.Predict(request, 5.0)  # 5 secs timeout\n",
    "\n",
    "outputs_tensor_proto = result.outputs[\"logits\"]\n",
    "shape = tf.TensorShape(outputs_tensor_proto.tensor_shape)\n",
    "outputs = tf.constant(list(outputs_tensor_proto.float_val), shape=shape)\n",
    "outputs = np.array(outputs_tensor_proto.float_val).reshape(shape.as_list())\n",
    "\n",
    "print(f'logits:{outputs}')\n",
    "\n",
    "outputs_tensor_proto = result.outputs[\"pred\"]\n",
    "shape = tf.TensorShape(outputs_tensor_proto.tensor_shape)\n",
    "outputs = tf.constant(list(outputs_tensor_proto.float_val), shape=shape)\n",
    "outputs = np.array(outputs_tensor_proto.float_val).reshape(shape.as_list())\n",
    "\n",
    "print(f'pred:{outputs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
